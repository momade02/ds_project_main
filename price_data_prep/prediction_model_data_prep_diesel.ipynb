{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca75cb0",
   "metadata": {},
   "source": [
    "# prediction_model data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247ca38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Connected to fuel_price_preparation.duckdb\n",
      "Connected to: C:\\Users\\websi\\OneDrive - UT Cloud\\Semester\\3. WS2025_26\\DS500 Data Science Project (12 ECTS)\\tankerkoenig_repo\\tankerkoenig-data\\fuel_price_preparation.duckdb\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration & Connection\n",
    "\n",
    "import duckdb\n",
    "import gc # Garbage Collector\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_DIR = Path(r\"C:\\Users\\websi\\OneDrive - UT Cloud\\Semester\\3. WS2025_26\\DS500 Data Science Project (12 ECTS)\\tankerkoenig_repo\\tankerkoenig-data\")\n",
    "DB_PATH = BASE_DIR / \"fuel_price_preparation.duckdb\"\n",
    "OUTPUT_PARQUET = BASE_DIR / \"derived\" / \"features_sampled_diesel_2023_2024.parquet\"\n",
    "\n",
    "# Globs\n",
    "PRICE_GLOBS = [\n",
    "    str(BASE_DIR / \"prices\" / \"2023\" / \"*\" / \"*-prices.csv\"),\n",
    "    str(BASE_DIR / \"prices\" / \"2024\" / \"*\" / \"*-prices.csv\")\n",
    "]\n",
    "STATION_GLOBS = [\n",
    "    str(BASE_DIR / \"stations\" / \"2023\" / \"*\" / \"*-stations.csv\"),\n",
    "    str(BASE_DIR / \"stations\" / \"2024\" / \"*\" / \"*-stations.csv\")\n",
    "]\n",
    "\n",
    "# --- ROBUST CONNECTION ---\n",
    "# 1. Force close any existing connection variables\n",
    "try:\n",
    "    if 'con' in globals():\n",
    "        con.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 2. Force Python to clear the memory (kill the \"Zombie\")\n",
    "gc.collect()\n",
    "\n",
    "# 3. Create the new connection\n",
    "try:\n",
    "    con = duckdb.connect(str(DB_PATH))\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "    con.execute(\"SELECT setseed(0.42);\")\n",
    "    print(f\"SUCCESS: Connected to {DB_PATH.name}\")\n",
    "except Exception as e:\n",
    "    print(\"ERROR: Could not connect. If using OneDrive, pause syncing or restart the kernel.\")\n",
    "    print(e)\n",
    "\n",
    "print(f\"Connected to: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbe4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf946b2d8bf48fd9ca972651aa15a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd1943dd2894b76b8101572a9403a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion Complete.\n",
      "┌──────────┬───────────┐\n",
      "│   type   │     n     │\n",
      "│ varchar  │   int64   │\n",
      "├──────────┼───────────┤\n",
      "│ Prices   │ 273916339 │\n",
      "│ Stations │  12523064 │\n",
      "└──────────┴───────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Ingestion (Bronze Layer) - CORRECTED\n",
    "\n",
    "# --- 1. Ingest Prices ---\n",
    "con.execute(\"DROP TABLE IF EXISTS prices_raw;\")\n",
    "\n",
    "# We use read_csv_auto for safety, but REMOVED 'SAMPLE_SIZE=-1' for speed.\n",
    "# 'union_by_name=true' handles cases where columns might be in different orders.\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE prices_raw AS \n",
    "    SELECT * FROM read_csv_auto(?, union_by_name=true);\n",
    "\"\"\", [PRICE_GLOBS]) \n",
    "\n",
    "# --- 2. Ingest Stations ---\n",
    "con.execute(\"DROP TABLE IF EXISTS stations_raw;\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE stations_raw AS \n",
    "    SELECT * FROM read_csv_auto(?, filename=true, union_by_name=true);\n",
    "\"\"\", [STATION_GLOBS])\n",
    "\n",
    "# --- 3. Sanity Check ---\n",
    "print(\"Ingestion Complete.\")\n",
    "con.sql(\"\"\"\n",
    "    SELECT 'Prices' as type, count(*) as n FROM prices_raw \n",
    "    UNION ALL \n",
    "    SELECT 'Stations', count(*) FROM stations_raw\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e8fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d916471d174adf83d74977dc5b8ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┐\n",
      "│ n_stations │\n",
      "│   int64    │\n",
      "├────────────┤\n",
      "│        500 │\n",
      "└────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Station Processing: Snapshot -> Sample -> Simple ID List\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS stations_final_sample;\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE stations_final_sample AS\n",
    "WITH parsed_stations AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        CAST(regexp_extract(filename, '([0-9]{4}-[0-9]{2}-[0-9]{2})', 1) AS DATE) AS snapshot_date\n",
    "    FROM stations_raw\n",
    "),\n",
    "latest_snapshot AS (\n",
    "    SELECT * EXCLUDE (rn) FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER (PARTITION BY uuid ORDER BY snapshot_date DESC) as rn\n",
    "        FROM parsed_stations\n",
    "    ) WHERE rn = 1\n",
    "),\n",
    "sampled_stations AS (\n",
    "    -- Randomly sample 500 stations\n",
    "    SELECT * FROM latest_snapshot ORDER BY random() LIMIT 500\n",
    ")\n",
    "SELECT \n",
    "    s.uuid AS station_uuid\n",
    "FROM sampled_stations s;\n",
    "\"\"\")\n",
    "\n",
    "con.sql(\"SELECT count(*) as n_stations FROM stations_final_sample\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbdcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f30bd1078ff4961a1b9e30cdac87ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┐\n",
      "│ count_star() │\n",
      "│    int64     │\n",
      "├──────────────┤\n",
      "│     15189613 │\n",
      "└──────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Price Gridding and Forward Fill\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS grid_sampled_diesel_prepared;\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE grid_sampled_diesel_prepared AS\n",
    "WITH \n",
    "-- 1. Filter prices to our 500 stations and diesel fuel only\n",
    "relevant_prices AS (\n",
    "    SELECT \n",
    "        p.station_uuid,\n",
    "        p.date as ts_raw,\n",
    "        CAST(p.diesel AS DOUBLE) as price_raw\n",
    "    FROM prices_raw p\n",
    "    WHERE p.station_uuid IN (SELECT station_uuid FROM stations_final_sample)\n",
    "      AND p.diesel IS NOT NULL AND p.diesel > 0\n",
    "),\n",
    "-- 2. Round timestamps to 30-minute floor, take average if multiple updates happen in 30 min\n",
    "prices_30min AS (\n",
    "    SELECT \n",
    "        station_uuid,\n",
    "        date_trunc('hour', ts_raw) + \n",
    "            INTERVAL (CASE WHEN EXTRACT(MINUTE FROM ts_raw) < 30 THEN 0 ELSE 30 END) MINUTE AS ts_30,\n",
    "        AVG(price_raw) as price_event\n",
    "    FROM relevant_prices\n",
    "    GROUP BY 1, 2\n",
    "),\n",
    "-- 3. Build the perfect Time Grid per station (min to max timestamp)\n",
    "station_bounds AS (\n",
    "    SELECT station_uuid, MIN(ts_30) as min_ts, MAX(ts_30) as max_ts \n",
    "    FROM prices_30min GROUP BY 1\n",
    "),\n",
    "full_grid AS (\n",
    "    SELECT sb.station_uuid, gs.ts_30\n",
    "    FROM station_bounds sb,\n",
    "    generate_series(sb.min_ts, sb.max_ts, INTERVAL 30 MINUTE) AS gs(ts_30)\n",
    "),\n",
    "-- 4. Join Grid with Events and Forward Fill (Optimized)\n",
    "joined_grid AS (\n",
    "    SELECT \n",
    "        g.station_uuid,\n",
    "        g.ts_30,\n",
    "        p.price_event\n",
    "    FROM full_grid g\n",
    "    LEFT JOIN prices_30min p ON g.station_uuid = p.station_uuid AND g.ts_30 = p.ts_30\n",
    ")\n",
    "-- Final Selection with Forward Fill\n",
    "SELECT\n",
    "    station_uuid,\n",
    "    ts_30,\n",
    "    -- MAGIC: Forward fill ignoring nulls replaces the complex recursive logic\n",
    "    LAST_VALUE(price_event IGNORE NULLS) OVER (\n",
    "        PARTITION BY station_uuid ORDER BY ts_30\n",
    "    ) AS price\n",
    "FROM joined_grid;\n",
    "\"\"\")\n",
    "\n",
    "# Validation: Ensure we didn't lose data\n",
    "con.sql(\"SELECT COUNT(*) FROM grid_sampled_diesel_prepared WHERE price IS NOT NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8404c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac00d3f1fa0143a29be18cce152c8a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to C:\\Users\\websi\\OneDrive - UT Cloud\\Semester\\3. WS2025_26\\DS500 Data Science Project (12 ECTS)\\tankerkoenig_repo\\tankerkoenig-data\\derived\\features_sampled_diesel_2023_2024.parquet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fb39b2838f4e9fa9c02e108eedfc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 5. Feature Engineering and Export (Optimized & Sorted)\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS features_final;\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE features_final AS\n",
    "WITH prepared_with_time AS (\n",
    "    SELECT \n",
    "        g.*,\n",
    "        timezone('Europe/Berlin', g.ts_30) AS ts_local,\n",
    "        CAST(timezone('Europe/Berlin', g.ts_30) AS DATE) AS d,\n",
    "        -- Calculate Time Cell (0-47)\n",
    "        (EXTRACT(HOUR FROM timezone('Europe/Berlin', g.ts_30)) * 2) + \n",
    "        (EXTRACT(MINUTE FROM timezone('Europe/Berlin', g.ts_30)) / 30) AS time_cell\n",
    "    FROM grid_sampled_diesel_prepared g\n",
    "    WHERE g.price IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    w.station_uuid,\n",
    "    w.d AS date,\n",
    "    w.time_cell, -- KEPT FOR SORTING ONLY\n",
    "    w.price,\n",
    "    \n",
    "    -- Lags\n",
    "    LAG(w.price, 1) OVER (PARTITION BY w.station_uuid, w.time_cell ORDER BY w.d) AS price_lag_1d,\n",
    "    LAG(w.price, 2) OVER (PARTITION BY w.station_uuid, w.time_cell ORDER BY w.d) AS price_lag_2d,\n",
    "    LAG(w.price, 3) OVER (PARTITION BY w.station_uuid, w.time_cell ORDER BY w.d) AS price_lag_3d,\n",
    "    LAG(w.price, 7) OVER (PARTITION BY w.station_uuid, w.time_cell ORDER BY w.d) AS price_lag_7d\n",
    "    \n",
    "FROM prepared_with_time w\n",
    "QUALIFY price_lag_1d IS NOT NULL AND price_lag_7d IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "output_dir = OUTPUT_PARQUET.parent\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Exporting to {OUTPUT_PARQUET}...\")\n",
    "con.execute(f\"COPY features_final TO '{OUTPUT_PARQUET}' (FORMAT PARQUET, COMPRESSION ZSTD);\")\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
