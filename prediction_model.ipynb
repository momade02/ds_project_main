{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00911616",
   "metadata": {},
   "source": [
    "# Data Science Project: Fuel Price Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb2828",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directory of the cloned tankerkoenig-data repo\n",
    "BASE_DIR = Path(\n",
    "    r\"C:\\Users\\websi\\OneDrive - UT Cloud\\Semester\\3. WS2025_26\\DS500 Data Science Project (12 ECTS)\\tankerkoenig_repo\\tankerkoenig-data\"\n",
    ")\n",
    "\n",
    "# DuckDB database file (will be created if it does not exist)\n",
    "DB_PATH = BASE_DIR / \"fuel_price_preparation.duckdb\"\n",
    "\n",
    "con = duckdb.connect(DB_PATH.as_posix())\n",
    "con.execute(\"PRAGMA threads=8;\")       # use multiple cores if available\n",
    "con.execute(\"SELECT setseed(0.42)\")  # fixed seed for reproducible random sampling\n",
    "\n",
    "print(f\"Connected to DuckDB at: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f624af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globs for 2023/2024 prices and stations\n",
    "prices_2023_glob = (BASE_DIR / \"prices\" / \"2023\" / \"*\" / \"*-prices.csv\").as_posix()\n",
    "prices_2024_glob = (BASE_DIR / \"prices\" / \"2024\" / \"*\" / \"*-prices.csv\").as_posix()\n",
    "\n",
    "stations_2023_glob = (BASE_DIR / \"stations\" / \"2023\" / \"*\" / \"*-stations.csv\").as_posix()\n",
    "stations_2024_glob = (BASE_DIR / \"stations\" / \"2024\" / \"*\" / \"*-stations.csv\").as_posix()\n",
    "\n",
    "print(prices_2023_glob)\n",
    "print(prices_2024_glob)\n",
    "print(stations_2023_glob)\n",
    "print(stations_2024_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26124cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Prices: read 2023 + 2024 into one table\n",
    "con.execute(\"DROP TABLE IF EXISTS prices_raw;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE prices_raw AS\n",
    "    SELECT * FROM read_csv_auto(?, SAMPLE_SIZE=-1)\n",
    "    UNION ALL\n",
    "    SELECT * FROM read_csv_auto(?, SAMPLE_SIZE=-1);\n",
    "    \"\"\",\n",
    "    [prices_2023_glob, prices_2024_glob],\n",
    ")\n",
    "\n",
    "# Quick sanity check\n",
    "con.execute(\"SELECT COUNT(*) AS n_rows, MIN(date), MAX(date) FROM prices_raw;\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Stations: read 2023 + 2024 into one table, also keep filename\n",
    "con.execute(\"DROP TABLE IF EXISTS stations_raw;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE stations_raw AS\n",
    "    SELECT\n",
    "        uuid,\n",
    "        name,\n",
    "        brand,\n",
    "        street,\n",
    "        house_number,\n",
    "        city,\n",
    "        latitude,\n",
    "        longitude,\n",
    "        first_active,\n",
    "        openingtimes_json,\n",
    "        filename\n",
    "    FROM read_csv_auto(\n",
    "            ?, \n",
    "            SAMPLE_SIZE=-1, \n",
    "            filename=true, \n",
    "            union_by_name=true\n",
    "         )\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        uuid,\n",
    "        name,\n",
    "        brand,\n",
    "        street,\n",
    "        house_number,\n",
    "        city,\n",
    "        latitude,\n",
    "        longitude,\n",
    "        first_active,\n",
    "        openingtimes_json,\n",
    "        filename\n",
    "    FROM read_csv_auto(\n",
    "            ?, \n",
    "            SAMPLE_SIZE=-1, \n",
    "            filename=true, \n",
    "            union_by_name=true\n",
    "         );\n",
    "    \"\"\",\n",
    "    [stations_2023_glob, stations_2024_glob],\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"SELECT COUNT(*) AS n_rows, MIN(uuid) AS min_uuid, MAX(uuid) AS max_uuid FROM stations_raw;\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Pick latest snapshot per station within 2023â€“2024\n",
    "con.execute(\"DROP TABLE IF EXISTS stations_snapshot;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE stations_snapshot AS\n",
    "    WITH parsed AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            -- extract 'YYYY-MM-DD' from filename, e.g. '.../2023-01-01-stations.csv'\n",
    "            CAST(regexp_extract(filename, '([0-9]{4}-[0-9]{2}-[0-9]{2})', 1) AS DATE) AS snapshot_date\n",
    "        FROM stations_raw\n",
    "    ),\n",
    "    ranked AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            ROW_NUMBER() OVER (PARTITION BY uuid ORDER BY snapshot_date DESC) AS rn\n",
    "        FROM parsed\n",
    "    )\n",
    "    SELECT\n",
    "        uuid,\n",
    "        name,\n",
    "        brand,\n",
    "        street,\n",
    "        house_number,\n",
    "        city,\n",
    "        CAST(latitude AS DOUBLE)  AS latitude,\n",
    "        CAST(longitude AS DOUBLE) AS longitude,\n",
    "        first_active,\n",
    "        openingtimes_json\n",
    "    FROM ranked\n",
    "    WHERE rn = 1;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"SELECT COUNT(*) AS n_rows, COUNT(DISTINCT uuid) AS n_uuids FROM stations_snapshot;\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef481d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Sample 500 random stations and compute brand groups (rare brands -> 'other')\n",
    "con.execute(\"DROP TABLE IF EXISTS stations_sampled;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE stations_sampled AS\n",
    "    WITH ranked AS (\n",
    "        SELECT\n",
    "            uuid,\n",
    "            brand,\n",
    "            city,\n",
    "            row_number() OVER (ORDER BY random()) AS rn\n",
    "        FROM stations_snapshot\n",
    "    )\n",
    "    SELECT\n",
    "        uuid,\n",
    "        brand,\n",
    "        city\n",
    "    FROM ranked\n",
    "    WHERE rn <= 500;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Brand grouping: brands with <= 5 stations in the 500-sample are mapped to 'other'\n",
    "con.execute(\"DROP TABLE IF EXISTS stations_sampled_grouped;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE stations_sampled_grouped AS\n",
    "    WITH brand_counts AS (\n",
    "        SELECT brand, COUNT(*) AS n\n",
    "        FROM stations_sampled\n",
    "        GROUP BY brand\n",
    "    ),\n",
    "    extended AS (\n",
    "        SELECT\n",
    "            s.uuid,\n",
    "            s.city,\n",
    "            CASE WHEN bc.n > 5 THEN s.brand ELSE 'other' END AS brand_group\n",
    "        FROM stations_sampled s\n",
    "        LEFT JOIN brand_counts bc USING (brand)\n",
    "    )\n",
    "    SELECT * FROM extended;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    SELECT brand_group, COUNT(*) AS n_stations\n",
    "    FROM stations_sampled_grouped\n",
    "    GROUP BY brand_group\n",
    "    ORDER BY n_stations DESC;\n",
    "    \"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 E5 price changes for the 500 sampled stations\n",
    "con.execute(\"DROP TABLE IF EXISTS prices_sampled_e5;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE prices_sampled_e5 AS\n",
    "    SELECT\n",
    "        CAST(p.date AS TIMESTAMP) AS ts,\n",
    "        p.station_uuid,\n",
    "        CAST(p.e5 AS DOUBLE) AS price_e5\n",
    "    FROM prices_raw p\n",
    "    JOIN stations_sampled_grouped s\n",
    "        ON s.uuid = p.station_uuid\n",
    "    WHERE p.e5 IS NOT NULL\n",
    "      AND p.e5 > 0;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) AS n_rows, MIN(ts) AS min_ts, MAX(ts) AS max_ts\n",
    "    FROM prices_sampled_e5;\n",
    "    \"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Round timestamps down to the nearest 30-minute grid cell\n",
    "con.execute(\"DROP TABLE IF EXISTS prices_sampled_e5_rounded;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE prices_sampled_e5_rounded AS\n",
    "    SELECT\n",
    "        station_uuid,\n",
    "        -- floor to 30-minute grid: 00 or 30\n",
    "        date_trunc('hour', ts)\n",
    "            + INTERVAL (CASE WHEN EXTRACT(MINUTE FROM ts) < 30 THEN 0 ELSE 30 END) MINUTE AS ts_30,\n",
    "        AVG(price_e5) AS price_e5\n",
    "    FROM prices_sampled_e5\n",
    "    GROUP BY station_uuid, ts_30;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) AS n_rows,\n",
    "           MIN(ts_30) AS min_ts_30,\n",
    "           MAX(ts_30) AS max_ts_30\n",
    "    FROM prices_sampled_e5_rounded;\n",
    "    \"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53193e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS grid_sampled_e5;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE grid_sampled_e5 AS\n",
    "    WITH station_span AS (\n",
    "        SELECT\n",
    "            station_uuid,\n",
    "            MIN(ts_30) AS min_ts,\n",
    "            MAX(ts_30) AS max_ts\n",
    "        FROM prices_sampled_e5_rounded\n",
    "        GROUP BY station_uuid\n",
    "    ),\n",
    "    grid AS (\n",
    "        -- 30-minute grid per station from first to last observed change\n",
    "        SELECT\n",
    "            s.station_uuid,\n",
    "            gs.ts_30\n",
    "        FROM station_span s,\n",
    "        generate_series(\n",
    "            s.min_ts,\n",
    "            s.max_ts,\n",
    "            INTERVAL 30 MINUTE\n",
    "        ) AS gs(ts_30)\n",
    "    ),\n",
    "    base AS (\n",
    "        -- attach price events (may be NULL if no change in this grid cell)\n",
    "        SELECT\n",
    "            g.station_uuid,\n",
    "            g.ts_30,\n",
    "            pr.price_e5 AS price_event\n",
    "        FROM grid g\n",
    "        LEFT JOIN prices_sampled_e5_rounded pr\n",
    "          ON pr.station_uuid = g.station_uuid\n",
    "         AND pr.ts_30       = g.ts_30\n",
    "    ),\n",
    "    numbered AS (\n",
    "        -- sequential index per station for forward-fill logic\n",
    "        SELECT\n",
    "            station_uuid,\n",
    "            ts_30,\n",
    "            price_event,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY station_uuid\n",
    "                ORDER BY ts_30\n",
    "            ) AS k\n",
    "        FROM base\n",
    "    ),\n",
    "    with_last_k AS (\n",
    "        -- for each row, compute index of last row with a non-null price_event\n",
    "        SELECT\n",
    "            station_uuid,\n",
    "            ts_30,\n",
    "            k,\n",
    "            MAX(\n",
    "                CASE\n",
    "                    WHEN price_event IS NOT NULL THEN k\n",
    "                    ELSE NULL\n",
    "                END\n",
    "            ) OVER (\n",
    "                PARTITION BY station_uuid\n",
    "                ORDER BY k\n",
    "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "            ) AS last_k\n",
    "        FROM numbered\n",
    "    ),\n",
    "    ff AS (\n",
    "        -- join back to get the forward-filled price\n",
    "        SELECT\n",
    "            n.station_uuid,\n",
    "            n.ts_30,\n",
    "            e.price_event AS price_e5\n",
    "        FROM with_last_k n\n",
    "        LEFT JOIN numbered e\n",
    "          ON e.station_uuid = n.station_uuid\n",
    "         AND e.k           = n.last_k\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM ff\n",
    "    WHERE price_e5 IS NOT NULL;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) AS n_rows,\n",
    "           MIN(ts_30) AS min_ts_30,\n",
    "           MAX(ts_30) AS max_ts_30\n",
    "    FROM grid_sampled_e5;\n",
    "    \"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ac347",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS grid_sampled_e5_prepared;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE grid_sampled_e5_prepared AS\n",
    "    SELECT\n",
    "        station_uuid,\n",
    "        ts_30 AS ts_utc,  -- Keep the original for reference if needed\n",
    "        \n",
    "        -- 1. Convert UTC timestamp to Berlin Local Time (Wall Time)\n",
    "        timezone('Europe/Berlin', ts_30) AS ts_local,\n",
    "        \n",
    "        -- 2. Use Local Time for the Date (so 01:00 AM stays on the correct day)\n",
    "        CAST(timezone('Europe/Berlin', ts_30) AS DATE) AS d,\n",
    "        \n",
    "        -- 3. Calculate the Time Cell (0..47) using Local Hour\n",
    "        (EXTRACT(HOUR FROM timezone('Europe/Berlin', ts_30)) * 2 \n",
    "         + EXTRACT(MINUTE FROM timezone('Europe/Berlin', ts_30)) / 30) AS time_cell,\n",
    "         \n",
    "        price_e5 AS price\n",
    "    FROM grid_sampled_e5;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Validation: Check if Rush Hour is stable\n",
    "con.execute(\"\"\"\n",
    "    SELECT \n",
    "        time_cell, \n",
    "        AVG(price) as mean_price \n",
    "    FROM grid_sampled_e5_prepared \n",
    "    GROUP BY time_cell \n",
    "    ORDER BY mean_price DESC \n",
    "    LIMIT 5;\n",
    "\"\"\").df()\n",
    "\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        MIN(d) AS min_date,\n",
    "        MAX(d) AS max_date,\n",
    "        MIN(time_cell) AS min_cell,\n",
    "        MAX(time_cell) AS max_cell\n",
    "    FROM grid_sampled_e5_prepared;\n",
    "    \"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcfd8423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count_star()",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "27947b03-2316-4d41-888f-2cf4b0c89bf4",
       "rows": [
        [
         "0",
         "14737608"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14737608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0      14737608"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 4.3 Feature Engineering: History + Seasonality + Momentum ---\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS features_sampled_e5;\")\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE features_sampled_e5 AS\n",
    "    WITH windows AS (\n",
    "        SELECT\n",
    "            g.station_uuid,\n",
    "            g.d,\n",
    "            g.time_cell,\n",
    "            g.price AS price_today,\n",
    "            \n",
    "            -- RAW HISTORY\n",
    "            LAG(g.price, 1) OVER (PARTITION BY g.station_uuid, g.time_cell ORDER BY g.d) AS price_lag_1d,\n",
    "            LAG(g.price, 2) OVER (PARTITION BY g.station_uuid, g.time_cell ORDER BY g.d) AS price_lag_2d,\n",
    "            LAG(g.price, 3) OVER (PARTITION BY g.station_uuid, g.time_cell ORDER BY g.d) AS price_lag_3d,\n",
    "            \n",
    "            -- WEEKLY HISTORY\n",
    "            LAG(g.price, 7)  OVER (PARTITION BY g.station_uuid, g.time_cell ORDER BY g.d) AS price_lag_7d,\n",
    "            LAG(g.price, 14) OVER (PARTITION BY g.station_uuid, g.time_cell ORDER BY g.d) AS price_lag_14d,\n",
    "            LAG(g.price, 21) OVER (PARTITION BY g.station_uuid, g.time_cell ORDER BY g.d) AS price_lag_21d\n",
    "            \n",
    "        FROM grid_sampled_e5_prepared g\n",
    "    )\n",
    "    SELECT\n",
    "        w.station_uuid,\n",
    "        w.d AS date,\n",
    "        w.time_cell,\n",
    "        w.price_today AS price,\n",
    "        \n",
    "        -- 1. NEW: Explicit Seasonality\n",
    "        -- dayofweek returns 0 for Sunday, 6 for Saturday in DuckDB\n",
    "        dayofweek(w.d) AS dow, \n",
    "        CASE WHEN dayofweek(w.d) IN (0, 6) THEN 1 ELSE 0 END AS is_weekend,\n",
    "        \n",
    "        -- 2. NEW: Price Momentum (Velocity)\n",
    "        -- \"Are we currently crashing or spiking compared to 2 days ago?\"\n",
    "        (w.price_lag_1d - w.price_lag_2d) AS mom_1d_2d,\n",
    "        (w.price_lag_1d - w.price_lag_7d) AS mom_1d_7d,\n",
    "\n",
    "        -- Standard Lags\n",
    "        w.price_lag_1d,\n",
    "        w.price_lag_2d,\n",
    "        w.price_lag_3d,\n",
    "        w.price_lag_7d,\n",
    "        w.price_lag_14d,\n",
    "        w.price_lag_21d,\n",
    "        \n",
    "        -- Brand\n",
    "        sb.brand_group\n",
    "        \n",
    "    FROM windows w\n",
    "    JOIN stations_sampled_grouped sb ON sb.uuid = w.station_uuid\n",
    "    WHERE w.price_lag_1d IS NOT NULL\n",
    "      AND w.price_lag_21d IS NOT NULL;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Check output\n",
    "con.execute(\"SELECT COUNT(*) FROM features_sampled_e5\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85f0d4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_uuid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "time_cell",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_weekend",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "mom_1d_2d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mom_1d_7d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_lag_1d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_lag_2d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_lag_3d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_lag_7d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_lag_14d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_lag_21d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "brand_group",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3677a377-0d2c-48df-97c5-7e773f9e068e",
       "rows": [
        [
         "0",
         "0627cc2b-d880-4c21-89bd-37e983c02624",
         "2023-01-21 00:00:00",
         "46.0",
         "2.249",
         "6",
         "1",
         "0.0",
         "-0.040000000000000036",
         "2.249",
         "2.249",
         "2.249",
         "2.289",
         "2.289",
         "2.289",
         "ARAL"
        ],
        [
         "1",
         "7915e506-168d-4509-a012-7cfba23fbc5c",
         "2023-01-21 00:00:00",
         "46.0",
         "2.249",
         "6",
         "1",
         "0.0",
         "0.010000000000000231",
         "2.249",
         "2.249",
         "2.249",
         "2.239",
         "2.239",
         "2.239",
         "ARAL"
        ],
        [
         "2",
         "9289d2c9-8d32-44ea-bf74-432d36c02425",
         "2023-01-21 00:00:00",
         "46.0",
         "1.829",
         "6",
         "1",
         "-0.050000000000000044",
         "-0.030000000000000027",
         "1.769",
         "1.819",
         "1.819",
         "1.799",
         "1.799",
         "1.759",
         "other"
        ],
        [
         "3",
         "0627cc2b-d880-4c21-89bd-37e983c02624",
         "2023-01-21 00:00:00",
         "47.0",
         "2.249",
         "6",
         "1",
         "0.0",
         "-0.040000000000000036",
         "2.249",
         "2.249",
         "2.249",
         "2.289",
         "2.289",
         "2.289",
         "ARAL"
        ],
        [
         "4",
         "1cf7a642-26bb-4dd4-a011-914025d0b7de",
         "2023-01-21 00:00:00",
         "47.0",
         "1.869",
         "6",
         "1",
         "0.0",
         "0.0",
         "1.849",
         "1.849",
         "1.829",
         "1.849",
         "1.789",
         "1.799",
         "TotalEnergies"
        ],
        [
         "5",
         "2822fc54-4d03-4a97-a3ab-1b00e04c5f46",
         "2023-01-21 00:00:00",
         "47.0",
         "1.779",
         "6",
         "1",
         "0.019999999999999796",
         "0.010000000000000009",
         "1.769",
         "1.749",
         "1.749",
         "1.759",
         "1.729",
         "1.729",
         "AVIA"
        ],
        [
         "6",
         "431170c0-24bf-47f3-85ca-46a2b307eefd",
         "2023-01-21 00:00:00",
         "47.0",
         "1.779",
         "6",
         "1",
         "0.010000000000000009",
         "0.029999999999999805",
         "1.779",
         "1.769",
         "1.769",
         "1.749",
         "1.759",
         "1.759",
         "TotalEnergies"
        ],
        [
         "7",
         "4b7e7978-b9ac-4013-9c28-c6afbfd4cb2d",
         "2023-01-21 00:00:00",
         "47.0",
         "1.749",
         "6",
         "1",
         "0.0",
         "0.0",
         "1.749",
         "1.749",
         "1.769",
         "1.749",
         "1.719",
         "1.749",
         "other"
        ],
        [
         "8",
         "59ca7896-2c19-4354-97a2-a0f1de18be4f",
         "2023-01-21 00:00:00",
         "47.0",
         "1.809",
         "6",
         "1",
         "0.0",
         "-0.019999999999999796",
         "1.749",
         "1.749",
         "1.749",
         "1.769",
         "1.759",
         "1.809",
         "other"
        ],
        [
         "9",
         "70726c80-fd30-45f8-87a6-8acf0c0000db",
         "2023-01-21 00:00:00",
         "47.0",
         "1.809",
         "6",
         "1",
         "0.010000000000000009",
         "0.040000000000000036",
         "1.829",
         "1.819",
         "1.779",
         "1.789",
         "1.819",
         "1.799",
         "TotalEnergies"
        ],
        [
         "10",
         "7915e506-168d-4509-a012-7cfba23fbc5c",
         "2023-01-21 00:00:00",
         "47.0",
         "2.249",
         "6",
         "1",
         "0.0",
         "0.010000000000000231",
         "2.249",
         "2.249",
         "2.249",
         "2.239",
         "2.239",
         "2.239",
         "ARAL"
        ],
        [
         "11",
         "83f4ae53-67d4-4a12-8239-41fe988e7281",
         "2023-01-21 00:00:00",
         "47.0",
         "1.789",
         "6",
         "1",
         "0.0",
         "0.030000000000000027",
         "1.789",
         "1.789",
         "1.779",
         "1.759",
         "1.759",
         "1.789",
         "TotalEnergies"
        ],
        [
         "12",
         "9289d2c9-8d32-44ea-bf74-432d36c02425",
         "2023-01-21 00:00:00",
         "47.0",
         "1.829",
         "6",
         "1",
         "-0.050000000000000044",
         "-0.030000000000000027",
         "1.769",
         "1.819",
         "1.819",
         "1.799",
         "1.799",
         "1.759",
         "other"
        ],
        [
         "13",
         "a1a785c7-3b02-44ca-b8ec-a42051736224",
         "2023-01-21 00:00:00",
         "47.0",
         "1.819",
         "6",
         "1",
         "0.010000000000000009",
         "0.030000000000000027",
         "1.809",
         "1.799",
         "1.799",
         "1.779",
         "1.759",
         "1.769",
         "TotalEnergies"
        ],
        [
         "14",
         "a8b2c574-1704-43a8-b271-3e9a87295f9d",
         "2023-01-21 00:00:00",
         "47.0",
         "1.789",
         "6",
         "1",
         "-0.020000000000000018",
         "0.0",
         "1.769",
         "1.789",
         "1.799",
         "1.769",
         "1.749",
         "1.779",
         "other"
        ],
        [
         "15",
         "c5f56fa3-a811-46f7-a6a2-e2e83f2ee576",
         "2023-01-21 00:00:00",
         "47.0",
         "1.809",
         "6",
         "1",
         "0.020000000000000018",
         "0.040000000000000036",
         "1.799",
         "1.779",
         "1.779",
         "1.759",
         "1.749",
         "1.739",
         "AVIA"
        ],
        [
         "16",
         "cbaaa8ac-8cbb-4043-8310-d65bfabb6975",
         "2023-01-21 00:00:00",
         "47.0",
         "1.839",
         "6",
         "1",
         "-0.010000000000000009",
         "0.050000000000000044",
         "1.819",
         "1.829",
         "1.809",
         "1.769",
         "1.709",
         "1.739",
         "other"
        ],
        [
         "17",
         "de208d1d-0999-4bf5-b6a4-abcccc7c079a",
         "2023-01-21 00:00:00",
         "47.0",
         "1.869",
         "6",
         "1",
         "0.010000000000000009",
         "-0.06000000000000005",
         "1.809",
         "1.799",
         "1.809",
         "1.869",
         "1.829",
         "1.849",
         "other"
        ],
        [
         "18",
         "0627cc2b-d880-4c21-89bd-37e983c02624",
         "2023-01-22 00:00:00",
         "0.0",
         "2.249",
         "0",
         "1",
         "0.0",
         "-0.040000000000000036",
         "2.249",
         "2.249",
         "2.249",
         "2.289",
         "2.289",
         "2.289",
         "ARAL"
        ],
        [
         "19",
         "1cf7a642-26bb-4dd4-a011-914025d0b7de",
         "2023-01-22 00:00:00",
         "0.0",
         "1.869",
         "0",
         "1",
         "0.0",
         "0.0",
         "1.849",
         "1.849",
         "1.829",
         "1.849",
         "1.789",
         "1.799",
         "TotalEnergies"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uuid</th>\n",
       "      <th>date</th>\n",
       "      <th>time_cell</th>\n",
       "      <th>price</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>mom_1d_2d</th>\n",
       "      <th>mom_1d_7d</th>\n",
       "      <th>price_lag_1d</th>\n",
       "      <th>price_lag_2d</th>\n",
       "      <th>price_lag_3d</th>\n",
       "      <th>price_lag_7d</th>\n",
       "      <th>price_lag_14d</th>\n",
       "      <th>price_lag_21d</th>\n",
       "      <th>brand_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0627cc2b-d880-4c21-89bd-37e983c02624</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.249</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.289</td>\n",
       "      <td>2.289</td>\n",
       "      <td>2.289</td>\n",
       "      <td>ARAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7915e506-168d-4509-a012-7cfba23fbc5c</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.249</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.239</td>\n",
       "      <td>ARAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9289d2c9-8d32-44ea-bf74-432d36c02425</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.829</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.759</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0627cc2b-d880-4c21-89bd-37e983c02624</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.249</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.289</td>\n",
       "      <td>2.289</td>\n",
       "      <td>2.289</td>\n",
       "      <td>ARAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cf7a642-26bb-4dd4-a011-914025d0b7de</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.869</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.829</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.799</td>\n",
       "      <td>TotalEnergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2822fc54-4d03-4a97-a3ab-1b00e04c5f46</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.779</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.729</td>\n",
       "      <td>1.729</td>\n",
       "      <td>AVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>431170c0-24bf-47f3-85ca-46a2b307eefd</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.779</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.759</td>\n",
       "      <td>TotalEnergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4b7e7978-b9ac-4013-9c28-c6afbfd4cb2d</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.749</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.719</td>\n",
       "      <td>1.749</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59ca7896-2c19-4354-97a2-a0f1de18be4f</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.809</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.809</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70726c80-fd30-45f8-87a6-8acf0c0000db</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.809</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.829</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.799</td>\n",
       "      <td>TotalEnergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7915e506-168d-4509-a012-7cfba23fbc5c</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.249</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.239</td>\n",
       "      <td>ARAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83f4ae53-67d4-4a12-8239-41fe988e7281</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.789</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.789</td>\n",
       "      <td>TotalEnergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9289d2c9-8d32-44ea-bf74-432d36c02425</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.829</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.759</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a1a785c7-3b02-44ca-b8ec-a42051736224</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.819</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.809</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.769</td>\n",
       "      <td>TotalEnergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a8b2c574-1704-43a8-b271-3e9a87295f9d</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.789</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.779</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c5f56fa3-a811-46f7-a6a2-e2e83f2ee576</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.809</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.739</td>\n",
       "      <td>AVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cbaaa8ac-8cbb-4043-8310-d65bfabb6975</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.839</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.819</td>\n",
       "      <td>1.829</td>\n",
       "      <td>1.809</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.739</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>de208d1d-0999-4bf5-b6a4-abcccc7c079a</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.869</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.809</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.809</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.829</td>\n",
       "      <td>1.849</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0627cc2b-d880-4c21-89bd-37e983c02624</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.249</td>\n",
       "      <td>2.289</td>\n",
       "      <td>2.289</td>\n",
       "      <td>2.289</td>\n",
       "      <td>ARAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1cf7a642-26bb-4dd4-a011-914025d0b7de</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.829</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.799</td>\n",
       "      <td>TotalEnergies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            station_uuid       date  time_cell  price  dow  \\\n",
       "0   0627cc2b-d880-4c21-89bd-37e983c02624 2023-01-21       46.0  2.249    6   \n",
       "1   7915e506-168d-4509-a012-7cfba23fbc5c 2023-01-21       46.0  2.249    6   \n",
       "2   9289d2c9-8d32-44ea-bf74-432d36c02425 2023-01-21       46.0  1.829    6   \n",
       "3   0627cc2b-d880-4c21-89bd-37e983c02624 2023-01-21       47.0  2.249    6   \n",
       "4   1cf7a642-26bb-4dd4-a011-914025d0b7de 2023-01-21       47.0  1.869    6   \n",
       "5   2822fc54-4d03-4a97-a3ab-1b00e04c5f46 2023-01-21       47.0  1.779    6   \n",
       "6   431170c0-24bf-47f3-85ca-46a2b307eefd 2023-01-21       47.0  1.779    6   \n",
       "7   4b7e7978-b9ac-4013-9c28-c6afbfd4cb2d 2023-01-21       47.0  1.749    6   \n",
       "8   59ca7896-2c19-4354-97a2-a0f1de18be4f 2023-01-21       47.0  1.809    6   \n",
       "9   70726c80-fd30-45f8-87a6-8acf0c0000db 2023-01-21       47.0  1.809    6   \n",
       "10  7915e506-168d-4509-a012-7cfba23fbc5c 2023-01-21       47.0  2.249    6   \n",
       "11  83f4ae53-67d4-4a12-8239-41fe988e7281 2023-01-21       47.0  1.789    6   \n",
       "12  9289d2c9-8d32-44ea-bf74-432d36c02425 2023-01-21       47.0  1.829    6   \n",
       "13  a1a785c7-3b02-44ca-b8ec-a42051736224 2023-01-21       47.0  1.819    6   \n",
       "14  a8b2c574-1704-43a8-b271-3e9a87295f9d 2023-01-21       47.0  1.789    6   \n",
       "15  c5f56fa3-a811-46f7-a6a2-e2e83f2ee576 2023-01-21       47.0  1.809    6   \n",
       "16  cbaaa8ac-8cbb-4043-8310-d65bfabb6975 2023-01-21       47.0  1.839    6   \n",
       "17  de208d1d-0999-4bf5-b6a4-abcccc7c079a 2023-01-21       47.0  1.869    6   \n",
       "18  0627cc2b-d880-4c21-89bd-37e983c02624 2023-01-22        0.0  2.249    0   \n",
       "19  1cf7a642-26bb-4dd4-a011-914025d0b7de 2023-01-22        0.0  1.869    0   \n",
       "\n",
       "    is_weekend  mom_1d_2d  mom_1d_7d  price_lag_1d  price_lag_2d  \\\n",
       "0            1       0.00      -0.04         2.249         2.249   \n",
       "1            1       0.00       0.01         2.249         2.249   \n",
       "2            1      -0.05      -0.03         1.769         1.819   \n",
       "3            1       0.00      -0.04         2.249         2.249   \n",
       "4            1       0.00       0.00         1.849         1.849   \n",
       "5            1       0.02       0.01         1.769         1.749   \n",
       "6            1       0.01       0.03         1.779         1.769   \n",
       "7            1       0.00       0.00         1.749         1.749   \n",
       "8            1       0.00      -0.02         1.749         1.749   \n",
       "9            1       0.01       0.04         1.829         1.819   \n",
       "10           1       0.00       0.01         2.249         2.249   \n",
       "11           1       0.00       0.03         1.789         1.789   \n",
       "12           1      -0.05      -0.03         1.769         1.819   \n",
       "13           1       0.01       0.03         1.809         1.799   \n",
       "14           1      -0.02       0.00         1.769         1.789   \n",
       "15           1       0.02       0.04         1.799         1.779   \n",
       "16           1      -0.01       0.05         1.819         1.829   \n",
       "17           1       0.01      -0.06         1.809         1.799   \n",
       "18           1       0.00      -0.04         2.249         2.249   \n",
       "19           1       0.00       0.00         1.849         1.849   \n",
       "\n",
       "    price_lag_3d  price_lag_7d  price_lag_14d  price_lag_21d    brand_group  \n",
       "0          2.249         2.289          2.289          2.289           ARAL  \n",
       "1          2.249         2.239          2.239          2.239           ARAL  \n",
       "2          1.819         1.799          1.799          1.759          other  \n",
       "3          2.249         2.289          2.289          2.289           ARAL  \n",
       "4          1.829         1.849          1.789          1.799  TotalEnergies  \n",
       "5          1.749         1.759          1.729          1.729           AVIA  \n",
       "6          1.769         1.749          1.759          1.759  TotalEnergies  \n",
       "7          1.769         1.749          1.719          1.749          other  \n",
       "8          1.749         1.769          1.759          1.809          other  \n",
       "9          1.779         1.789          1.819          1.799  TotalEnergies  \n",
       "10         2.249         2.239          2.239          2.239           ARAL  \n",
       "11         1.779         1.759          1.759          1.789  TotalEnergies  \n",
       "12         1.819         1.799          1.799          1.759          other  \n",
       "13         1.799         1.779          1.759          1.769  TotalEnergies  \n",
       "14         1.799         1.769          1.749          1.779          other  \n",
       "15         1.779         1.759          1.749          1.739           AVIA  \n",
       "16         1.809         1.769          1.709          1.739          other  \n",
       "17         1.809         1.869          1.829          1.849          other  \n",
       "18         2.249         2.289          2.289          2.289           ARAL  \n",
       "19         1.829         1.849          1.789          1.799  TotalEnergies  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM features_sampled_e5\n",
    "    ORDER BY date, time_cell, station_uuid\n",
    "    LIMIT 20;\n",
    "    \"\"\"\n",
    ").df()\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f5328d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce020f44384b496a87ade27c914220bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported features to: C:\\Users\\websi\\OneDrive - UT Cloud\\Semester\\3. WS2025_26\\DS500 Data Science Project (12 ECTS)\\tankerkoenig_repo\\tankerkoenig-data\\derived\\features_sampled_e5_2023_2024.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Export features to Parquet ---\n",
    "output_dir = BASE_DIR / \"derived\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_parquet = output_dir / \"features_sampled_e5_2023_2024.parquet\"\n",
    "\n",
    "sql = f\"\"\"\n",
    "COPY features_sampled_e5\n",
    "TO '{output_parquet.as_posix()}'\n",
    "(FORMAT PARQUET, COMPRESSION ZSTD);\n",
    "\"\"\"\n",
    "\n",
    "con.execute(sql)\n",
    "\n",
    "print(f\"Exported features to: {output_parquet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d9a3a",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Path to features parquet (no market / markup, no post_code)\n",
    "BASE_DIR = Path(\n",
    "    r\"C:\\Users\\websi\\OneDrive - UT Cloud\\Semester\\3. WS2025_26\\DS500 Data Science Project (12 ECTS)\\tankerkoenig_repo\\tankerkoenig-data\"\n",
    ")\n",
    "\n",
    "features_path = BASE_DIR / \"derived\" / \"features_sampled_e5_2023_2024.parquet\"\n",
    "\n",
    "df = pd.read_parquet(features_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6680f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Type Optimization ---\n",
    "\n",
    "# 1. FIX: Convert 'date' to Timestamp\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"time_cell\"] = df[\"time_cell\"].astype(\"int16\")\n",
    "\n",
    "# 2. Ensure correct types for all history features\n",
    "cols_to_fix = [\n",
    "    \"price_lag_1d\", \"price_lag_2d\", \"price_lag_3d\",\n",
    "    \"price_lag_7d\", \"price_lag_14d\", \"price_lag_21d\"\n",
    "]\n",
    "\n",
    "for c in cols_to_fix:\n",
    "    df[c] = df[c].astype(\"float32\")\n",
    "\n",
    "# 3. Sort for safety\n",
    "df = df.sort_values([\"station_uuid\", \"date\", \"time_cell\"]).reset_index(drop=True)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cut dates\n",
    "train_end = pd.Timestamp(\"2024-06-30\")\n",
    "valid_end = pd.Timestamp(\"2024-09-30\")\n",
    "\n",
    "train_mask = df[\"date\"] <= train_end\n",
    "valid_mask = (df[\"date\"] > train_end) & (df[\"date\"] <= valid_end)\n",
    "test_mask  = df[\"date\"] > valid_end\n",
    "\n",
    "print(\"Train rows:\", train_mask.sum())\n",
    "print(\"Valid rows:\", valid_mask.sum())\n",
    "print(\"Test rows :\", test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ffdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define target and features ---\n",
    "\n",
    "target_col = \"price\"\n",
    "\n",
    "feature_cols = [\n",
    "    \"time_cell\",        # The \"When\"\n",
    "    \"brand_group\",      # The \"Who\"\n",
    "    \n",
    "    # Recent History (Short term state)\n",
    "    \"price_lag_1d\", \n",
    "    \"price_lag_2d\", \n",
    "    \"price_lag_3d\",\n",
    "    \n",
    "    # Seasonal History (Day-of-week state)\n",
    "    \"price_lag_7d\",\n",
    "    \"price_lag_14d\",\n",
    "    \"price_lag_21d\",\n",
    "]\n",
    "\n",
    "cat_cols = [\"brand_group\"]\n",
    "\n",
    "# --- Time-based train/validation/test split ---\n",
    "\n",
    "train_end = pd.Timestamp(\"2024-06-30\")\n",
    "valid_end = pd.Timestamp(\"2024-09-30\")\n",
    "\n",
    "train_mask = df[\"date\"] <= train_end\n",
    "valid_mask = (df[\"date\"] > train_end) & (df[\"date\"] <= valid_end)\n",
    "test_mask  = df[\"date\"] > valid_end\n",
    "\n",
    "print(\"Train rows:\", train_mask.sum())\n",
    "print(\"Valid rows:\", valid_mask.sum())\n",
    "print(\"Test rows :\", test_mask.sum())\n",
    "\n",
    "X_train = df.loc[train_mask, feature_cols].copy()\n",
    "y_train = df.loc[train_mask, target_col].values\n",
    "\n",
    "X_valid = df.loc[valid_mask, feature_cols].copy()\n",
    "y_valid = df.loc[valid_mask, target_col].values\n",
    "\n",
    "X_test = df.loc[test_mask, feature_cols].copy()\n",
    "y_test = df.loc[test_mask, target_col].values\n",
    "\n",
    "# Cast categoricals\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype(\"category\")\n",
    "    X_valid[c] = X_valid[c].astype(\"category\")\n",
    "    X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629414a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def mae_rmse(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mae, rmse\n",
    "\n",
    "# Baseline 1: yesterday same time (Lag 1d)\n",
    "b1_pred = df.loc[test_mask, \"price_lag_1d\"].values\n",
    "b1_mae, b1_rmse = mae_rmse(y_test, b1_pred)\n",
    "\n",
    "# Baseline 2: week-ago same time (Lag 7d)\n",
    "b2_pred = df.loc[test_mask, \"price_lag_7d\"].values\n",
    "b2_mae, b2_rmse = mae_rmse(y_test, b2_pred)\n",
    "\n",
    "# Baseline 3: simple average of last 3 days (Smoothing baseline)\n",
    "b3_pred = (df.loc[test_mask, \"price_lag_1d\"].values + \n",
    "           df.loc[test_mask, \"price_lag_2d\"].values + \n",
    "           df.loc[test_mask, \"price_lag_3d\"].values) / 3.0\n",
    "b3_mae, b3_rmse = mae_rmse(y_test, b3_pred)\n",
    "\n",
    "print(\"Baseline metrics on TEST set\")\n",
    "print(f\"Yesterday:   MAE={b1_mae:.4f}, RMSE={b1_rmse:.4f}\")\n",
    "print(f\"Week-ago:    MAE={b2_mae:.4f}, RMSE={b2_rmse:.4f}\")\n",
    "print(f\"Avg(3days):  MAE={b3_mae:.4f}, RMSE={b3_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- 1. Create Datasets (Same as before) ---\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=cat_cols,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    categorical_feature=cat_cols,\n",
    "    reference=train_data,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "# --- 2. Define the Grid Search ---\n",
    "# We focus on complexity (num_leaves) and robustness (min_data_in_leaf)\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 63, 127],\n",
    "    \"min_data_in_leaf\": [100, 200, 500],\n",
    "    \"learning_rate\": [0.05] \n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"Starting Grid Search with {len(combinations)} candidates...\\n\")\n",
    "\n",
    "best_score = float(\"inf\")\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "# --- 3. Run the Loop ---\n",
    "for i, config in enumerate(combinations):\n",
    "    \n",
    "    # Base parameters (fixed settings)\n",
    "    current_params = {\n",
    "        \"objective\": \"mae\",\n",
    "        \"metric\": \"mae\",\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"max_bin\": 255,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "    # Update with current grid values\n",
    "    current_params.update(config)\n",
    "    \n",
    "    # Train\n",
    "    # We use a smaller patience (20) for the grid search to speed it up\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=20, verbose=False),\n",
    "        lgb.log_evaluation(period=0) # Silence the training logs\n",
    "    ]\n",
    "    \n",
    "    gbm_candidate = lgb.train(\n",
    "        current_params,\n",
    "        train_set=train_data,\n",
    "        num_boost_round=1000, \n",
    "        valid_sets=[train_data, valid_data],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Get the best score (MAE on validation set)\n",
    "    score = gbm_candidate.best_score[\"valid\"][\"l1\"]\n",
    "    \n",
    "    print(f\"[{i+1}/{len(combinations)}] Params: {config} -> Val MAE: {score:.5f}\")\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = current_params\n",
    "        best_model = gbm_candidate\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"WINNER: MAE = {best_score:.5f}\")\n",
    "print(\"Best Params:\", best_params)\n",
    "print(\"=\"*40)\n",
    "\n",
    "# --- 4. Set the winner ---\n",
    "# This ensures the next cells use the best model found\n",
    "gbm = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd245e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best iteration determined by early stopping\n",
    "y_pred_test = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "lgb_mae, lgb_rmse = mae_rmse(y_test, y_pred_test)\n",
    "\n",
    "print(\"LightGBM metrics on TEST set\")\n",
    "print(f\"LightGBM:    MAE={lgb_mae:.4f}, RMSE={lgb_rmse:.4f}\")\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Yesterday:   MAE={b1_mae:.4f}, RMSE={b1_rmse:.4f}\")\n",
    "print(f\"Week-ago:    MAE={b2_mae:.4f}, RMSE={b2_rmse:.4f}\")\n",
    "print(f\"Avg(y,7d):   MAE={b3_mae:.4f}, RMSE={b3_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce857690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = gbm.feature_importance(importance_type=\"gain\")\n",
    "for col, imp in sorted(zip(feature_cols, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{col:15s} {imp:.1f}\")\n",
    "\n",
    "# Simple bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "order = np.argsort(importances)\n",
    "plt.barh(np.array(feature_cols)[order], importances[order])\n",
    "plt.xlabel(\"Importance (gain)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk for later use\n",
    "model_path = BASE_DIR / \"derived\" / \"lightgbm_sampled_e5_mae.txt\"\n",
    "gbm.save_model(model_path.as_posix())\n",
    "print(f\"Saved LightGBM model to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f841c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stations = con.execute(\"SELECT DISTINCT station_uuid FROM features_sampled_e5 LIMIT 5\").df()\n",
    "print(valid_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(station_uuid, query_time_str, con, gbm):\n",
    "    \"\"\"\n",
    "    Robustly predicts fuel price.\n",
    "    Fixes date comparison issues and enforces column ordering.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # 1. Setup Query\n",
    "    query_ts = pd.Timestamp(query_time_str)\n",
    "    \n",
    "    # Calculate Time Cell (0..47)\n",
    "    time_cell = (query_ts.hour * 2) + (1 if query_ts.minute >= 30 else 0)\n",
    "    \n",
    "    # Calculate Lags\n",
    "    target_date = query_ts.date()\n",
    "    lag_days = [1, 2, 3, 7, 14, 21]\n",
    "    dates_to_fetch = [target_date - pd.Timedelta(days=d) for d in lag_days]\n",
    "    \n",
    "    # Convert to strings for safe SQL and Python comparison\n",
    "    date_strs = [d.isoformat() for d in dates_to_fetch]\n",
    "    \n",
    "    # 2. Fetch History\n",
    "    # We cast 'd' to VARCHAR in SQL to ensure it comes back as a string in Pandas\n",
    "    # This prevents the \"datetime.date vs Timestamp\" mismatch error completely.\n",
    "    query = f\"\"\"\n",
    "    WITH history AS (\n",
    "        SELECT \n",
    "            CAST(d AS VARCHAR) as d_str, \n",
    "            price \n",
    "        FROM grid_sampled_e5_prepared \n",
    "        WHERE station_uuid = '{station_uuid}'\n",
    "          AND time_cell = {time_cell}\n",
    "          AND d IN (\n",
    "              CAST('{date_strs[0]}' AS DATE),\n",
    "              CAST('{date_strs[1]}' AS DATE),\n",
    "              CAST('{date_strs[2]}' AS DATE),\n",
    "              CAST('{date_strs[3]}' AS DATE),\n",
    "              CAST('{date_strs[4]}' AS DATE),\n",
    "              CAST('{date_strs[5]}' AS DATE)\n",
    "          )\n",
    "    ),\n",
    "    brand_info AS (\n",
    "        SELECT brand_group \n",
    "        FROM stations_sampled_grouped \n",
    "        WHERE uuid = '{station_uuid}'\n",
    "    )\n",
    "    SELECT \n",
    "        h.d_str, \n",
    "        h.price,\n",
    "        b.brand_group\n",
    "    FROM history h, brand_info b\n",
    "    \"\"\"\n",
    "    \n",
    "    history_df = con.execute(query).df()\n",
    "    \n",
    "    if history_df.empty:\n",
    "        print(f\"Warning: No history found for St: {station_uuid}, Cell: {time_cell}\")\n",
    "        # Fallback: return None or a default value\n",
    "        return None\n",
    "\n",
    "    # 3. Construct Features safely\n",
    "    features = {\n",
    "        \"time_cell\": time_cell,\n",
    "        \"brand_group\": history_df[\"brand_group\"].iloc[0]\n",
    "    }\n",
    "    \n",
    "    # Helper: Match strings to strings\n",
    "    def get_price(date_str):\n",
    "        row = history_df[history_df[\"d_str\"] == date_str]\n",
    "        if not row.empty:\n",
    "            return float(row[\"price\"].values[0])\n",
    "        return np.nan\n",
    "\n",
    "    # Map prices\n",
    "    features[\"price_lag_1d\"] = get_price(date_strs[0])\n",
    "    features[\"price_lag_2d\"] = get_price(date_strs[1])\n",
    "    features[\"price_lag_3d\"] = get_price(date_strs[2])\n",
    "    features[\"price_lag_7d\"] = get_price(date_strs[3])\n",
    "    features[\"price_lag_14d\"] = get_price(date_strs[4])\n",
    "    features[\"price_lag_21d\"] = get_price(date_strs[5])\n",
    "    \n",
    "    # Debug Print: Check if we actually found data\n",
    "    found_lags = sum(1 for k,v in features.items() if \"price_lag\" in k and not np.isnan(v))\n",
    "    print(f\"Debug: Found {found_lags}/6 historical prices for {query_time_str}\")\n",
    "\n",
    "    # 4. Create DataFrame and Enforce Order\n",
    "    X_input = pd.DataFrame([features])\n",
    "    \n",
    "    # Cast types\n",
    "    X_input[\"brand_group\"] = X_input[\"brand_group\"].astype(\"category\")\n",
    "    for col in X_input.columns:\n",
    "        if \"price_lag\" in col:\n",
    "            X_input[col] = X_input[col].astype(\"float32\")\n",
    "            \n",
    "    # CRITICAL: Reorder columns to match exactly what LightGBM expects\n",
    "    # gbm.feature_name() gives the list of features from training\n",
    "    X_input = X_input[gbm.feature_name()]\n",
    "    \n",
    "    # 5. Predict\n",
    "    prediction = gbm.predict(X_input)[0]\n",
    "    return prediction\n",
    "\n",
    "# --- TEST AGAIN ---\n",
    "# (Make sure to use a valid UUID from your training set)\n",
    "test_station = \"78f22673-eee8-4577-81da-b6062309dda1\" \n",
    "test_time_1 = \"2024-10-01 17:00:00\"\n",
    "test_time_2 = \"2024-10-01 18:00:00\"\n",
    "\n",
    "p1 = predict_price(test_station, test_time_1, con, gbm)\n",
    "p2 = predict_price(test_station, test_time_2, con, gbm)\n",
    "\n",
    "print(f\"17:00 Price: {p1:.3f}\")\n",
    "print(f\"18:00 Price: {p2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
